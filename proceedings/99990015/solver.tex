\subsection{Overview}\label{subsec:overview}
A (candidate) execution can be determined by a
total ordering (permutation) of memory stores to each location (CO),
and an association of a unique store to each load (RF).  (They can
conflict PO, i.e. the initial order of instructions in threads.)  Relations
between instructions are modelled by CHR
constraints. % that are added into the store as soon as they are found.
To compute admissible executions of a program under a given model, we
generate all candidate executions (represented by the aforementioned
relations), and filter them on-the-fly using CHR rules defined for the
model.  The set of candidate executions is easily generated (in our
case, by a Prolog program using backtrack) by enumerating all
possibilities of these relations.  Without additional constraints,
this set contains the executions authorized by a very weak generic
model~\cite{AMT2014:TPLS} allowing lots of intuitively incoherent
behaviors (e.g. where, within the same thread, an old value that has been overwritten 
can still be read from the location after the overwriting operation).

To keep only executions allowed by the target memory model, 
we define CHR rules to filter out cases where the relations between 
instructions of a given execution are inadmissible. 
The principle is to compute the transitive closure of certain ordering 
relations (depending on the model) that the execution must satisfy according 
to the model. If the computed transitive closure exhibits a cycle, 
then, according to the model, some program instruction
has to be executed strictly before itself, which is incoherent: the execution
is not allowed. If this closure has no cycles, the ordering relations 
are admissible and the execution is allowed by the model.
To efficiently use CHRs, we declare all CHR rules needed by the model before
the Prolog program, so that they detect incoherent executions 
as early as possible during their generation.

\medskip\noindent
\textbf{Language.}
%\paragraph{Language.} %We start with 
An input program is modelled by the list of declared variables and the list
of lists of instructions of its threads. The implementation of $p_0$ and $p_1$
in Prolog is shown in Fig.~\ref{fig:programs}b, lines 4--6, 8--10.
The considered instructions are either a memory operation (load or store) or a fence.
%An memory operation can be a load \texttt{ld} or a store \texttt{st}.
A load (resp. a store) is a tuple "(ld, loc, v)" 
(resp. "(st, loc, v)") where "loc" is the read
(resp. written) location and "v" its value. 
% NK: may be not useful here ?
%% Both location
%% and value can be provided as constants or variables by the user, and
%% can be associated to a named register using a syntax of the form
%% \texttt{name:value/location} \commentNK{needed?}. It is useful when we want to create a
%% dependency between instructions for example.
A fence, written "f(OP1,OP2)", takes as parameters the types
of instructions whose order we want to force. For example, by writing
"f(st, ld)", we state that any store preceding this fence
is ordered strictly before any load following the fence.
The notation "any" expresses ``any type of operation''. For
example, "f(ld, any)" states that all loads preceding the
fence are ordered before any instruction that follows it. 


%\medskip\noindent
\subsection{The Generic Model}
%\paragraph{The Generic Model.}
\label{subsec:generic-model}
A first step is to take the list of instructions of each thread and to enrich them 
by the thread identifier and instruction index in the list. 
As we perform this operation, we also create 
CHR constraints "i/5, fence/4" for memory operations and fences of the form 
"i(n_thread, n_inst,  op, loc, v)" and "fence(n_thread, n_inst, t_op1, t_op2)".
In this model we consider PO, CO, RF, FR and barrier relations, defined by 
CHR constraints "po/2, co/2, rf/2, fr/2, barrier/2".  
We extract "po" relation by reading the list of instructions of each thread and setting 
"po" for two consecutive memory operations in it.
For example, the constraint "po(i(0,0,st,x,1),i(0,1,ld,y,R0))" will be generated to
represent the program order of the two instructions  $i_{00}$ and $i_{01}$ of thread 0 of $p_0$ 
in Fig.~\ref{fig:programs}a. We also define "ipo", the transitive closure of "po".

The relations CO and RF are generated by enumerating all possible solutions in a straightforward way.
The CO relation is obtained after generating a permutation of all stores to each memory location
(with an additional store at the beginning to write $undefined$),
and setting the constraints "co(i1,i2)" for any two consecutive stores "(...,i1,i2,...)"
in the permutation. 
The RF relation  associates each load to
a possible origin store. 
For the example of execution of Sec.~\ref{sect:weakMemoryModels},
returning $\mathtt{r_0 = 1}$ and $\mathtt{r_1 = 0}$, the constraints are 
"rf(i(1,0,st,y,1),i(0,1,ld,y,1))" and, as we add a store to $undefined$ for
initialization, "rf(i(-1,-1,st,x,undefined), i(1,1,ld,x,undefined))".
Notice that the read values (here, Prolog variables \texttt{R0,R1}) 
are unified with the written ones. The "-1" value of "n_thread, n_inst"
indicates the initial definition of  the program memory state.
% of the memory before program
%execution.
%% \commentNK{For the example of Sec. \ref{sect:weakMemoryModels},
%% the constraints \texttt{rf(i(?,?,?,?,?),i(?,?,?,?,?))} and 
%% \texttt{rf(i(?,?,?,?,?),i(?,?,?,?,?))} are defined for
%% the execution $\pi$ returning $\mathtt{r_0 = 1}$ and $\mathtt{r_1 = 0}$.}

The relation FR is computed by two rules:
"rf(ST,LD), co(ST, ST2) ==> fr(LD,ST2)"
and "fr(LD,ST), co(ST,ST2) ==> fr(LD,ST2)".
The first one means ``if there is a
RF-relation between \texttt{ST} and \texttt{LD}, and there is a
CO-relation between \texttt{ST} and \texttt{ST2}, then add a
FR-relation between \texttt{LD} and \texttt{ST2}''.
The second adds the subsequent overwritings, if any.

Finally, we have some CHR rules that, taking the set of instruction
constraints and the set of fence constraints, produce \texttt{barrier}
constraints that force order on instructions. 
One example for $p_1$ in Fig.~\ref{fig:programs}a is 
\texttt{barrier(i(0,0,st,x,1),i(0,2,ld,y,R0))}.

%\medskip\noindent
\subsection{Cycle Detection}\label{subsec:cycleDetect}
%\paragraph{Formalization of a memory model.}
Basically a memory model is defined by the relations between
instructions that are allowed by the model. As these relations
between two instructions express which one appears before the other, we
can transitively produce all chains of dependencies. If a chain is a
cycle, the execution exhibits an incoherence, since it means that an
instruction happens before itself.
The detection of a cycle is done by the CHR code of
%defined in
Fig. \ref{fig:cycleDetection}.
%a file "cycle.pl":

\begin{figure}
\begin{lstlisting}[language=chr,basicstyle=\footnotesize\ttfamily]
:- chr_constraint rel/3, trace/3, cycle/2.
trace(R,Begin,End) \ trace(R,Begin,End) <=> true.
trace(R,Begin,End), rel(R,End,Begin) <=> cycle(R,Begin).
trace(R,Begin,End), rel(R,End,Next) ==> inf(Begin,Next) | trace(R,Begin,Next).
rel(R,Begin,End) ==> inf(Begin,End) | trace(R,Begin,End).
\end{lstlisting}
%% %\vspace*{-2mm}
\caption{Cycle detection (file \texttt{cycle.pl}).}
%% %\vspace*{-3mm}
\label{fig:cycleDetection}
\end{figure}

We use three CHR constraints. Constraint  "rel(R,Begin,End)" 
states that instructions "Begin, End" are related by relation "R".
The transitive closure "trace(R,Begin,End)" 
means that "Begin, End" are transitively related 
by a trace, that is, a chain of relations "R", while
"cycle(R,Begin)" indicates that a cycle is found from "Begin" to itself.

%% We need three CHR constraints "rel" has 3 parameters: the
%% considered relation, and the two related instructions~; "trace"
%% has 3 parameters: the considered relation, the first and last
%% instructions of the trace~; "cycle" has 2 parameters: the
%% considered relation, and the instruction from where we found a cycle.

The first rule (line 2) is a {\em simpagation} rule, written
"A \ B <=> C". The meaning is ``if there exist two constraints
"A" and "B", add "C", keep "A" and remove
"B"''. So here, the goal is to remove duplicate traces
with the same origin and end, as they
will generate the same final traces.

The  {\em simplification} rule at line 3 expresses that, 
if we have a trace from "Begin" to
"End", and we find a relation between "End" and "Begin", 
we have to replace these two constraints by a new one
that indicates the existence of a cycle starting from "Begin".

The third rule produces the transitive closure by adding longer traces whenever
it finds a relation to continue an existing trace, unless it leads to a cycle 
since the cycle detection is fired by the previous rule. 
The order of rules is thus essential for performance.
To optimize the search further and to limit 
the quantity of traces we work on, we consider an arbitrary total order "inf" on 
instructions, and we add an instruction to a growing trace only if it is 
strictly greater (w.r.t. "inf") than the origin of the trace. Indeed, 
since we compute traces from every instruction at the same time, 
to detect any cycle it is sufficient to compute
traces going only through instructions 
strictly greater than the trace origin (cf. %we detail this point in 
Sec.~\ref{subsec:discuss}). We ensure 
this behavior by the CHR syntax "R ==> Guard | N" which says ``if we match 
\texttt{R}, add \texttt{N} only if "Guard" is true''.

The fourth rule selects every known relation between two instructions and adds
it as a cycle candidate "trace" (using the same optimization by "inf" as above).
% If we want to keep only correct executions, and not only tag incorrect ones,
% we can add a rule that in case of cycle detection produce a constraint store
% that contains false by writing \texttt{cycle(_,_) <=> false}. By doing
% this, we only keep correct executions.

If we wish to keep only allowed executions, we 
can optimize the constraint 
filtering even further and add another rule "cycle(_,_) <=> false" that 
fails whenever a cycle is detected. 
Thus, inadmissible executions will be rejected as soon as detected.

%\medskip\noindent
\subsection{Formalization of a Memory Model}\label{subsec:formalization}
To formalize a model we first identify the relations that it preserves
and we create a new relation that we name according to the model
acronym.  Each occurrence of a preserved relation will create a new
constraint with this name. The goal is then to produce the transitive
closure and to launch the detection of cycles for this constraint.

For example, SC preserves the relations PO, CO, RF and FR
% mentioned in the subsection 
%\ref{subsec:generic-model}, 
and it does not care about barriers (since instructions 
are necessarily kept in order due to PO). 
We will name the new relation "sc".
Fig. \ref{fig:models}a shows how we model 
it with CHR. 
\begin{figure}
  \begin{subfigure}[t]{.43\textwidth}
    \begin{adjustbox}{width=.975\textwidth,keepaspectratio}
\begin{lstlisting}[language=chr]
:- include(generic_model).
:- include(cycle).
:- chr_constraint sc/2.

sc(I0,I1) ==> rel(sc, I0, I1).

sc(I0,I1), sc(I0,I1) <=> sc(I0,I1).
po(I0,I1) ==> sc(I0,I1).
co(I0,I1) ==> sc(I0,I1).
rf(I0,I1) ==> sc(I0,I1).
fr(I0,I1) ==> sc(I0,I1).
\end{lstlisting}}
    \end{adjustbox}
  \end{subfigure}
~~~
  \begin{subfigure}[t]{0.57\textwidth}
    \begin{adjustbox}{width=.975\textwidth,keepaspectratio}
\begin{lstlisting}[language=chr]
:- include(generic_model).
:- include(uniproc).
:- chr_constraint rfe/2 , ppo/2, tso/2.
% po-WR pairs are not preserved by TSO
ppo(i(_,_,st,_,_), i(_,_,ld,_,_)) <=> true.
ipo(I0,I1) ==> ppo(I0,I1).

ext(i(T0,_,_,_,_), i(T1,_,_,_,_)):- \+ T0 = T1.
rf(I0,I1) ==> ext(I0,I1) | rfe(I0, I1).

tso(I0,I1) ==> rel(tso, I0, I1).
barrier(I0,I1) ==> tso(I0,I1).
ppo(I0,I1)     ==> tso(I0,I1).
rfe(I0,I1)     ==> tso(I0,I1).
co(I0,I1)      ==> tso(I0,I1).
fr(I0,I1)      ==> tso(I0,I1).
\end{lstlisting}
\end{adjustbox}
%\caption{TSO model}
%\label{fig:tso-model}
  \end{subfigure}
\vspace*{-2mm}
\caption{Solver files for memory models (a) SC and (b) TSO}
\vspace*{-3mm}
\label{fig:models}
\end{figure}
Line 5 launches the computation of the transitive closure. 
Basically, every time we find a constraint "sc(A,B)"
we add a new constraint "rel(sc, A, B)". The cycle detection
is provided by the inclusion of "cycle.pl", line 2. 
Cycle rules and "rel" rule are added before any other rule about SC, 
to ensure the earliest detection of cycles.
Lines 7--11 show how to state that "sc" preserves other relations.
Every time such a relation is met, we add a new
"sc"-relation. % for the same instructions.

Another interesting case is when the target model
is more relaxed, that is, when the model preserves only some relations 
of the generic model. 
% and not all of them.
%described in~\ref{subsec:generic-model} and not all of them. 
For example the TSO model 
will relax two kinds of relations: program order when the instructions are a store 
followed by a load, and read-from when the two instructions are in the same 
thread. The reordering propagates transitively: multiple stores can be reordered 
after consecutive loads.
If the developer wants to restore these relations, they will have to add 
fences. This model is illustrated in Fig.~\ref{fig:models}b.

We add a relation named "ppo" (``preserved-program-order''). Every
relation "ipo" will generate a relation "ppo" except the ones mentioned
before.  So we add the rule on line 5, that replaces every constraint
"ppo(store, load)" by ``true'', which means that we just remove it,
and a rule (line 6) that will generate "ppo" from "ipo". %Again, the order
%of the rules is here important as we detail in Sec.~\ref{subsec:discuss}.
We add another relation named "rfe" (``read-from-external''). The associated rule
(lines 8--9) builds "rfe"-relations from "rf" by only adding those that
concern instructions in different threads.  Finally, we create the "tso"
relations as for SC. Again, the order of rules here is essential for 
both soundness and performance (cf. Sec.~\ref{subsec:discuss}).

Most weak memory models respect a coherency between communications
(CO, RF, FR) and PO per location. In essence, it restores
the uni-processor coherency (e.g. it forbids to read an old value from
an overwritten location, that is allowed by the generic
model, as mentioned in Sec. \ref{subsec:overview}). 
It is formalized in the included "uniproc" file (not detailed here),
which includes and relies on "cycle", so we do not have to include it again.

The implementation of the PSO model is quite straightforward once
TSO is implemented. It consists in weakening the preserved-program-order 
a bit more by removing all "ipo"-pairs starting with a store
instead of only removing store-load pairs. Concretely, we 
replace the rule line 5 in the TSO model by the following one:
"ppo(i(_,_,st,_,_), _) <=> true".


\medskip\noindent
\textbf{Applying the solver to programs.}
%\paragraph{Apply the model to programs.}
The application of the solver for a given model to a program is 
performed automatically as illustrated in 
Fig~\ref{fig:programs}b for program $p_0$ described in 
Sec.~\ref{sect:weakMemoryModels}. 
%
%% \begin{figure}[t]
%% \begin{lstlisting}[language=chr]
%% :- include(sc). % or else::- include(tso).
%
%% sbnofc([x,y], [T1,T2]) :- T1 = [ (st,x,1), (ld,y,R1) ],             |   x  <- 1   ||   y  <- 1
%%                           T2 = [ (st,y,1), (ld,x,R2) ].             |   R1 <- y   ||   R2 <- x
%%                                                                     |
%% sbfc([x,y], [T1,T2]) :-  T1 = [ (st,x,1), f(any,any), (ld,y,R1) ],  |   x  <- 1   ||   y  <- 1
%%                          T2 = [ (st,y,1), f(any,any), (ld,x,R1) ].  |   fence     ||   fence
%%                                                                     |   R1 <- y   ||   R2 <- x
%% ?- sb_nofc(Vars, Threads), apply_generic_model(Vars, Threads).
%% \end{lstlisting}
%% \caption{Example of use of the solver}
%% \label{fig:apply-model}
%% \end{figure}
%
We include the target model, that already includes 
the generic model with all other necessary definitions.
%Since the definition of the specific memory model needs definition
%created in the generic model, we do not have to 
%include it.\commentNK{unclear, rephrase} We just
%have to include the targeted memory model, that adds all CHR that will
%detect an incoherence.  
The program is loaded using two variables
(variables involved in the program and lists of instructions of threads).
Applying the target model solver to the program (line 13)  will generate all candidate
executions, and the CHR rules of the model will determine if each
execution is allowed by the model or not.

In this case the SC model detects 3 admissible
executions for both programs $p_0$ and $p_1$.
The TSO model allows 4 admissible executions for  $p_0$,
while for  $p_1$, as we have fences, some relations will
be restored and TSO will allow only 3 executions (exactly as SC).
TSO allows more executions than 
SC on $p_0$ since ST/LD pairs of instructions can be reordered
(that can lead to the result $\mathtt{r_0 = 0}$ and $\mathtt{r_1 = 0}$).
In $p_1$, we restore the sequentially consistent behavior of $p_0$ by adding fences, 
preventing reordering even in the TSO model.

%\medskip\noindent
\subsection{Discussion on Soundness and Performance}
\label{subsec:discuss}
%\textbf{Order of rules.} 
While using CHR, the order of rules
can be essential for both soundness and performance. 
We emphasize two particular points regarding the order of rules in the proposed solver:
cycle detection and computation of preserved-program-order relation "ppo".

In cycle detection (cf. Fig. \ref{fig:cycleDetection}), we want to ensure that the solver does not 
miss any traces and avoids to consider equivalent traces when possible.
%and that it terminates. %, that is, it cannot generate infinite traces.
%We have already argued on generation of equivalent traces in Sec. \ref{subsec:cycleDetect}. 
First, as mentioned in Sec. \ref{subsec:cycleDetect}, the rule
at line 2 in Fig. \ref{fig:cycleDetection} removes equivalent traces 
that have exactly the same origin and end points. As it is the first rule, 
we will not waste time by using the following rules for two equivalent traces 
since we will keep only one of them. 
Second, trace generation starts simultaneously from all known
relations "rel(R,Begin,End)" where instruction "Begin" is less than "End", while  
other instructions are added at the end of a trace only if they are greater than its origin (lines 4--5).
So, every cycle has a minimal instruction from which we can find this cycle
as a trace from an origin through greater instructions followed by a return to 
the origin, cf. line 3. (Notice that we 
still need to consider subtraces of the same cycle when they start from other nodes.)
%That means that once a 
%trace has to continue to an instruction smaller than its origin, it will stop growing. 
Third, the addition of an
instruction to a trace (line 4) is done by adding a new constraint, 
without removing the ``old'' ones that can still be necessary to 
generate other grown traces, so we do not miss paths.

%% The termination is ensured by the fact that the rule used to detect cycles (line 3)
%% removes both the trace and the relation that completes the cycle, and this rule is
%% placed (and thus activated) before the trace generation rules. So a trace
%% cannot grow any more whenever a cycle is detected. Thus, since the number of instructions is
%% finite, we cannot generate infinite traces.

When defining a relation such as preserved-program-order "ppo" (cf. Sec. \ref{subsec:formalization}), there are
two ways to proceed: to define preserved relations or to define  removed relations. The 
first way is always sound (as we only add information), while the second one requires
more care. In particular, it is important to place the rule which
removes relaxed relations before the rules that generate the constraints for
cycle detection (see e.g. lines 5--6, 11, 13 in Fig. \ref{fig:models}b). 
Otherwise, these rules would generate constraints for cycle 
detection before the relaxed relation is actually removed from the store 
and could thus forbid allowed executions.






\medskip\noindent
\textbf{Experiments.} We tested our solver for different models against
18 examples\footnote{Examples available at
\url{http://virginia.cs.ucl.ac.uk/herd/} (record ``armed cats'').}
provided for the implementation of a dedicated tool Herd~\cite{AMT2014:TPLS}. 
On these small (but representative) examples, our solver returns the same allowed 
executions as those found by Herd. 

Execution time on these examples being too fast, 
we also compare performances of our solver with Herd on some
examples involving a series of (possibly wrong) message passing. 
Experiments have been performed on an Intel Core i7-4800MQ, 4 cores, 2.7Ghz, 16Go RAM.
For example, the following  code involves three message passing: 
\begin{lstlisting}[language=chr,basicstyle=\small\ttfamily]
mp3(V, [T0,T1,T2]) :-
  V  = [ x, m ] ,
  T0 = [(st,x,1), (st,m,1), (ld,m,M0),(ld,x,X0)],
  T1 = [(ld,m,M1),(ld,x,X1),(st,x,2) ,(st,m,2) ],
  T2 = [(ld,m,M2),(ld,x,X2),(st,x,3) ,(st,m,3) ].
\end{lstlisting}
In such an example, the typical question is: if we get "M0 = 3",
"M1 = 1" and "M2 = 2", do we get "X0 = 3", "X1 = 1" and "X2 = 2"?

\begin{wraptable}{o}{.46\linewidth}
\begin{tabular}{|l||l|r|r|}
\hline
Model                    & Data      & 3MP    & 4MP   \\
\hline
\multirow{3}{*}{SC}      & \#exec    & 678    & 81\,882 \\
                         & CHR  & 3.3s   & 747s  \\
                         & Herd & 5.5s   & $>$ 1h\\
\hline
\multirow{3}{*}{TSO}     & \#exec    & 800    & 96\,498 \\
                         & CHR  & 3.2s   & 752s  \\
                         & Herd & 4.1s   & $>$ 1h\\
\hline
\multirow{3}{*}{PSO}     & \#exec    & 2\,258   & 516\,030\\
                         & CHR  & 6.4s   & 2796s \\
                         & Herd & 3.8s   & $>$ 1h\\
\hline
\multirow{3}{*}{Generic} & \#exec    & 147\,436 & 255\,000\,000 \\
                         & CHR  & 3.3s   & $>$ 1h\\
                         & Herd & 1.2s   & 1405s \\
\hline
\end{tabular}
\end{wraptable}
As it is composed of multiple writes and reads to the same locations, 
the combinatorial explosion is very fast. For each model, we indicate the 
number of allowed executions and the time needed to compute them with our CHR-based
solver and with Herd. 
The timeout is fixed to 1 hour. The number 
of executions indicated for the generic model corresponds to the 
number of candidate executions. We present here the results for 3 and 
4 message passings (denoted 3MP and 4MP). 

In this benchmark, our solver is configured to immediately reject 
forbidden executions as soon as they are detected, while Herd does not perform 
such early rejections.
When combinatorial explosion becomes really big, our solver computes allowed executions
faster than Herd thanks to an early pruning of the search tree.

% Local Variables: ***
% eval: (ispell-change-dictionary "english" nil) ***
% mode: latex ***
% eval: (flyspell-buffer) ***
% End: ***

% LocalWords: CHR Prolog SC TSO
